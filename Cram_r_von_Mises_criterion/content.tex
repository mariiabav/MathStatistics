\newpage
\listoftables


\newpage
\section{Постановка задачи}
Сгенерировать выборку для нормального распределения $N(x, \mu, \sigma)$.
По сгенерированной выборке оценить параметры $\mu$ и $\sigma$ нормального закона методом максимального правдоподобия. В качестве основной гипотезы $H_0$ будем считать, что сгенерированное распределение имеет вид $N(x, \hat{\mu}, \hat{\sigma})$. Проверить основную гипотезу, используя критерий Мизеса-Смирнова. В качестве уровня значимости рекоменудется взять $\alpha = 0.01$ или $\alpha = 0.02$.
\addcontentsline{toc}{section}{Постановка задачи}

\section{Теория}
\subsection{Метод максимального правдоподобия}

Пусть $x_1, ... , x_n$ — случайная выборка из генеральной совокупности с плотностью вероятности $f(x,  \theta)$; $L(x_1, ... x_n, \theta)$ — функция правдоподобия(ФП), представляющая собой совместную плотность вероятности независимых с.в. $x_1, ... x_n$ и рассматриваемая как функция неизвестного параметра $\theta$:
\begin{equation} \label{eq:Lfirst}
L(x_1, ... x_n, \theta) = f(x_1,  \theta) f(x_2,  \theta) ... f(x_n,  \theta)
\end{equation}

\textbf{Определение.} Оценкой максимального правдоподобия (о.м.п) будем называть такое значение $\hat{\theta}_{mp}$ из множества допустимых значений параметра $\theta$, для которого ФП принимает наибольшее значение при заданных $x_1, ... , x_n$:
\begin{equation} \label{eq:omega}
  \hat{\theta}_{mp} = arg max L(x_1, ... x_n, \theta)
\end{equation}

Если ФП дважды дифференцируема, то её стационарные значения даются корнями уравнения
\begin{equation} \label{eq:K}
  \frac{\partial L(x_1, ... x_n, \theta)}{\partial \theta} = 0
\end{equation}

Достаточным условием того, чтобы некоторое стационарное значение $\widetilde{\theta}$ было локальным максимумом, является неравенство
\begin{equation} \label{eq:K}
  \frac{\partial^2 L(x_1, ... x_n, \widetilde{\theta})}{\partial \theta^2} < 0
\end{equation}

Определив точки локальных максимумов ФП (если их несколько), находят наибольший, который и даёт решение задачи \ref{eq:Lfirst}.
Часто проще искать максимум логарифма ФП, так как он имеет максимум в одной точке с ФП:
\begin{equation} \label{eq:K}
  \frac{\partial ln L}{\partial \theta} = \frac{1}{L} \frac{\partial L}{\partial \theta}, L > 0, 
\end{equation}
и соответственно решать уравнение
\begin{equation} \label{eq:K}
  \frac{\partial ln L}{\partial \theta} = 0, 
\end{equation}
которое называют уравнением правдоподобия.

В задаче оценивания векторного параметра $\theta = (\theta_1, ... , \theta_m) $ аналогично \ref{eq:omega} находится максимум ФП нескольких аргументов:
\begin{equation} \label{eq:theta}
  \hat{\theta}_{mp} = arg max L(x_1, ... x_n, \theta_1, ..., \theta_m),
\end{equation}
и в случае дифференцируемости ФП выписывается система уравнений правдоподобия
\begin{equation} \label{eq:K}
  \frac{\partial L}{\partial \theta_k} = 0  \text{ или } \frac{\partial ln L}{\partial \theta_k} = 0, \\ k = 1, ..., m
\end{equation}

\textbf{Пример.} Оценивание м.о. $m$ и дисперсии $\sigma^2 $ нормального распределения $N(m, \sigma)$. \\
Составим функцию правдоподобия и получим последовательно:
\begin{equation} \label{eq:K}
   L(x_1, ... x_n, m, \sigma) = \prod\limits_{n = 1} \frac{1}{\sigma \sqrt{2\pi}} exp\left\{-\frac{(x_i-m)^2}{2\sigma^2}\right\} = (2\pi\sigma^2)^{-n/2} exp\left\{-\frac{1}{2\sigma^2} \sum (x_i-m)^2\right\},
\end{equation}
\begin{equation} \label{eq:K}
   lnL = -\frac{n}{2} ln2\pi - \frac{n}{2} ln\sigma^2 - \frac{1}{2\sigma^2}\sum (x_i-m)^2.
\end{equation}
Получим следующие уравнения правдоподобия:
\begin{equation} \label{eq:systen}
 \begin{cases}
 \frac{\partial ln L}{\partial m} = \frac{1}{\hat{\theta^2}} \sum(x_i-\hat{m}) = \frac{n}{\hat{\theta}^2}(\overline{x}-\hat{m}) = 0, \\
 
 \frac{\partial ln L}{\partial (\sigma^2)} = -\frac{n}{2\hat{\sigma}^2} + \frac{1}{2(\hat{\sigma}^2)^2} \sum (x_i - \hat{m})^2 = \frac{n}{2(\hat{\sigma}^2)^2} [\frac{1}{n}\sum (x_i - \hat{m})^2 - \hat{\sigma}^2] = 0,
 \end{cases}
\end{equation}
откуда следует, что выборочное среднее $\overline{x}$ — о.м.п. математического ожидания: $\hat{m}_{мп} = \overline{x}$, а выборочная дисперсия $s^2 = \frac{1}{n} \sum (x_i - \overline{x})^2$ — о.м.п. генеральной дисперсии: $\hat{\sigma}^2_{mp} = s^2$. \cite{theory}

\subsection{Проверка гипотезы о законе распределения генеральной совокупности. Критерий Мизеса—Смирнова}
Построим закон распределения приближённо на основе статистических данных. \\ 
Сначала выдвинем гипотезу о виде закона распределения $H_0$ с функцией распределения $F(x)$. \\ 
После того как выбран вид закона, произведем оценку его параметров. \\
Для проверки гипотезы о законе распределения применим критерий Мизеса-Смирнова. Критерий Мизеса—Смирнова использует статистику, имеющую вид

\begin{equation} \label{eq:omega} 
 \omega_n^2[\Psi(F)] = \int_{-\infty}^{\infty} [F_n(x)-F(x)]^2\Psi[F(x)]dF(x),
\end{equation}
где $F(x)-$ теоретическая функция распределения;\\
$F_n(x)-$ эмпирическая функция распределения;\\
$\Psi[F(x)]-$ весовая функция, область определения которой представляет собой область значений функции $F(x)$. \\
Как правило, используют весовые функции двух видов: $\Psi[F]=1$, при которой все значения функции распределения обладают одинаковым весом, и  $\Psi[F]=\frac{1}{F(1-F)}$, при которой вес результатов измерений увеличивается на «хвостах» распределений. В приведенном критерии использована весовая функция второго вида, поскольку на практике различия между распределениями наиболее отчетливы в области крайних значений. Однако почти всегда малое число результатов измерений имеется как раз в области крайних значений. Поэтому целесообразно придать этим результатам больший вес. Если принять весовую функцию второго вида, то статистика $n\omega_n^2$ после выполнения интегрирования имеет вид 

\begin{equation} \label{eq:Г1}
  n\omega_n^2[1/F(1-F)] = n\omega_n^2 = -n -2\sum  {\frac{2j-1}{2n} lnF(x_j) + (1-\frac{2j-1}{2n})ln[1-F(x_j)])},
\end{equation}
где $F(x_j) -$ значение функции теоретического распределения при значении аргумента, равном $x_j(j=1, …, n)$. \\
$x_1 < x_2 < ...< x_n - $ результаты измерений, упорядоченные по значению.


Статистика подчиняется асимптотическому (при $n \rightarrow{} \infty $) распределению:
\begin{equation} \label{eq:P}
  P(n\omega_n^2 < x) = a(x) = \frac{\sqrt{2\pi}}{x} \sum (-1)^j \frac{\Gamma(j +\frac{1}{2})}{\Gamma(\frac{1}{2})\Gamma(j+1)} (4j+1) e^{-\frac{(4j+1)^2\pi^2}{8x}} \int_0^\infty e^{\frac{x}{8(y^2+1)}-\frac{(4j+1)^2\pi^2y^2}{8x}} dy.
\end{equation}


Применение критерия требует выполнения большого объема вычислительных операций, но этот критерий более мощный, чем критерий Пирсона. Число результатов измерений при использовании этого критерия должно быть более 50.

\textbf{Правило проверки гипотезы о законе распределения с использованием критерия Мизеса-Смирнова.}
\begin{enumerate} 
\item Вычисляют значение статистики $n\Omega_n^2$ по формуле \ref{eq:Г1}. \\
Промежуточные вычисления по формуле \ref{eq:Г1} рекомендуется сводить в таблицу. После заполнения таблицы суммируют значения, внесенные в ее последний столбец. Значение величины $n\Omega_n^2$ находят, подставляя полученную сумму в формулу  \ref{eq:Г1}.
\item По таблице находят значение функции распределения $a(x)$ для $x$, равного вычисленному значению $n\Omega_n^2$.
\item Задают уровень значимости $\alpha$. Рекомендуется выбирать значение $\alpha$, равное 0,1 или 0,2.
\item Если $a>(1-\alpha)$,то гипотезу о согласии эмпирического и теоретического распределений отвергают,если $a<(1-\alpha)$, то гипотезу принимают.
\end{enumerate}
\section{Реализация}
Курсовая работа была выполнена с помощью встроенных средств языка программирования Python в среде разработки IDLE. Исходный код лабораторной работы приведён по ссылке. В ходе работы использовались библиотеки Math, Matplotlib и Numpy.
Помимо основных в ходе работы были использованы следующие инструменты: 
\begin{itemize}
    \item norm.cdf: значение функции распределения стандартного нормального распределения при заданном значении 
    \item statistics.variance: выборочное среднее квадратическое отклонение результатов измерений
    \item numpy.mean: среднее арифметическое значение результатов измерений
\end{itemize}


\section{Результаты}
\subsection{Проверка гипотезы о законе распределения генеральной совокупности. Критерий Мизеса-Смирнова}

\textbf{Пример 1.} 

Пример 1 составлен при малом количестве данных в целях иллюстрации сложного вычислительного процесса при использовании критерия Мизеса-Смирнова.

Метод максимального правдоподобия:
\begin{center}
    $\hat{\mu} \approx 25,4087, \hat{\sigma} \approx 4,3241$
\end{center} 

Сумма значений, приведенных в столбце 10 таблицы, равна $-7.579982$. \\

Тогда результат вычислений по формуле \ref{eq:Г1} будет $n\Omega_n^2 = -n - 2(-7.579982) = 0.159964 \approx 0.16$. \\

Значение функции $a(x)$, в соотвествии с таблицей, для $x=n\Omega_n^2=0.16$ равно 0,001. \\

Уровень значимости $\alpha = 0.2$. \\ 

Гипотеза о том, что выборка принадлежит нормально распределенной генеральной совокупности, не может быть отвергнута, так как $0.001 < 0.8$.

\textbf{Пример 2.} 

Метод максимального правдоподобия:
\begin{center}
    $\hat{\mu} \approx -0.0635, \hat{\sigma} \approx 1.0511$
\end{center} 

Сумма значений, приведенных в столбце 10 таблицы, равна $-15.276805$. \\

Тогда результат вычислений по формуле \ref{eq:Г1} будет $n\Omega_n^2 = -n - 2(-15.276805) = 0.553611 \approx 0.55$. \\

Значение функции $a(x)$, в соотвествии с таблицей, для $x=n\Omega_n^2=0.55$ равно 0,294. \\

Уровень значимости $\alpha = 0.2$. \\ 

Гипотеза о том, что выборка принадлежит нормально распределенной генеральной совокупности, не может быть отвергнута, так как $0,294 < 0.8$.